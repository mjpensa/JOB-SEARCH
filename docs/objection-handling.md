# Objection Handling

These are the most likely challenges in interviews, with approved responses. Use these proactively in interview prep and, when relevant, weave preemptive versions into cover letters.

---

## Objection 1: "You don't have a CS degree or formal technical background."

**Response:** My role is not to build AI systems — it's to govern, enable, and advise on them. I developed hands-on fluency through self-directed prototyping specifically to understand the risk surface at a practitioner level. I can speak to retrieval failure modes, agentic workflow risks, and data lineage challenges from firsthand experience — but I'm not positioning as an engineer. I'm the person who translates between the engineering team, the business, and the regulator.

---

## Objection 2: "You've never deployed a model to production."

**Response:** Correct — and that's by design. My value is in defining what needs to be true before a model reaches production: the validation framework, the controls, the governance sign-off, the monitoring requirements. I've built prototypes specifically to understand where production risks emerge, so I can design governance frameworks that are grounded in reality rather than theoretical.

---

## Objection 3: "Your AI experience is only one year old."

**Response:** My AI governance experience is built on ten years of regulatory risk management in financial services. The governance disciplines — risk assessment, controls design, cross-functional alignment, regulatory response — are the same. What I've added in the past year is deep fluency with the specific technology, which I developed deliberately through hands-on prototyping. The combination is what makes this profile unusual.

---

## Objection 4: "Can you do quantitative model validation?"

**Response:** I'm not a quant. My strength is on the governance architecture and program management side — designing the framework, defining the controls, coordinating across lines of defense, and ensuring regulatory readiness. For quantitative validation, I'd partner with model risk specialists. I've coordinated between operational, technology, market, and third-party risk specialists throughout my career — that cross-functional orchestration is exactly what AI governance programs need.

---

## Objection 5: "Your prototyping was all self-directed, not in a professional context."

**Response:** That's partially true — the initial prototyping was self-directed, but at BIP I prototyped AI-enabled automation tools professionally as part of building the firm's AI Risk Governance practice. The self-directed work was intentional: I invested my own time to develop firsthand understanding of the technology because I believe governance professionals who've never touched the systems they oversee can't design effective controls. Every prototype was chosen to map to a real financial services use case — document retrieval over regulatory policy, agentic automation in enterprise systems, AI-generated compliance deliverables. The insights I gained directly inform how I'd approach governance in a professional setting.

---

## Objection 6: "You had a short tenure at BIP and a gap before that — should we be concerned about stability?"

**Response:** Both transitions were driven by market conditions, not performance. I left EY after four years when the engagement wound down, and BIP underwent an organizational restructuring. What I'd point to is what I accomplished in that time: at BIP, I built the AI Risk Governance practice from scratch — defined the service offering, prototyped AI-enabled tools, and delivered resolution planning model oversight at Citi. Before that, at EY, I led governance programs at Wells Fargo, Bank of America, and MasterCard. Consulting is project-based by nature — the question isn't tenure, it's impact per engagement. I'm now looking for a role where I can build something durable, which is exactly why AI governance at a financial institution is the right fit.
